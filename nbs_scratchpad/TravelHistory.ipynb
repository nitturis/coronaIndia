{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json\n",
    "\n",
    "with urllib.request.urlopen(\n",
    "    \"https://api.steinhq.com/v1/storages/5e736c1db88d3d04ae0815b3/Raw_Data\"\n",
    ") as url:\n",
    "    data = json.loads(url.read().decode())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meghanabhange/.pyenv/versions/3.7.3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30               Travelled from Thailand and Malaysia\n",
       "31                                Travelled from Iran\n",
       "32                                Travelled from Iran\n",
       "33                                Travelled from Oman\n",
       "34    Travelled from Italy on 29/02/2020 through Doha\n",
       "Name: Notes, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Notes\"][30:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "def get_travel_status(span):\n",
    "    if span.label_ ==\"GPE\":\n",
    "        prev_token = span.doc[span.start - 1]\n",
    "        if prev_token.text in (\"from\", \"through\", \"via\", \"Via\"):\n",
    "            return(\"from\")\n",
    "        elif prev_token.text in (\"to\", \"and\"):\n",
    "            return(\"to\")\n",
    "        return \"to\"\n",
    "\n",
    "# Register the Span extension as 'travel_status'\n",
    "Span.set_extension(\"travel_status\", getter=get_travel_status, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Indian', 'Indian')]\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span, Token\n",
    "\n",
    "def get_nat(span):\n",
    "    if span.label_ ==\"NORP\":\n",
    "        return span.text\n",
    "\n",
    "# Register the Span extension as 'nationality'\n",
    "Span.set_extension(\"nationality\", getter=get_nat, force=True)\n",
    "\n",
    "doc = nlp(\"Indian Tourist\")\n",
    "print([(ent.text, ent._.nationality) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('friend', None), ('and', None), ('family', None), ('of', 'friend and family'), ('p23', None)]\n"
     ]
    }
   ],
   "source": [
    "def get_rel(token):\n",
    "    if token.text == \"of\":\n",
    "        prev_token = token.doc[token.i - 1]\n",
    "        prev2 = None\n",
    "        if token.i > 2:\n",
    "            prev2 = token.doc[token.i - 2]\n",
    "            if prev2.text.lower() == \"and\":\n",
    "                return f\"{token.doc[token.i - 3]} {token.doc[token.i - 2]} {token.doc[token.i - 1]}\"\n",
    "        if prev_token.text.lower() in (\"members\", \"member\"):\n",
    "            return \"Family Member\"\n",
    "        else:\n",
    "            return prev_token.text\n",
    "\n",
    "\n",
    "# Register the Span extension as 'relationship'\n",
    "Token.set_extension(\"relationship\", getter=get_rel, force=True)\n",
    "\n",
    "doc = nlp(\"friend and family of p23\")\n",
    "print([(ent.text, ent._.relationship) for ent in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relationship(sent):\n",
    "    if not sent:\n",
    "            return []\n",
    "    s = re.sub(r'[^\\w\\s]',' ',sent)\n",
    "    doc = nlp(s)\n",
    "    for tok in doc:\n",
    "        if tok._.relationship:\n",
    "            return(tok._.relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_travel_place(sent):\n",
    "    if not sent:\n",
    "            return []\n",
    "    s = re.sub(r'[^\\w\\s]',' ',sent)\n",
    "    doc = nlp(s)\n",
    "    travel = []\n",
    "    for ent in doc.ents:\n",
    "        if ent._.travel_status:\n",
    "            travel.append(ent.text)\n",
    "    return travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nationality(sent):\n",
    "    if not sent:\n",
    "            return []\n",
    "    s = re.sub(r'[^\\w\\s]',' ',sent)\n",
    "    doc = nlp(s)\n",
    "    nat = []\n",
    "    for ent in doc.ents:\n",
    "        if ent._.nationality:\n",
    "            nat.append(ent._.nationality)\n",
    "    return nat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json\n",
    "\n",
    "with urllib.request.urlopen(\n",
    "    \"https://raw.githubusercontent.com/bhanuc/indian-list/master/state-city.json\"\n",
    ") as url:\n",
    "    state_city = json.loads(url.read().decode())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\"India\", \"Mumbai\"]\n",
    "for k, v in state_city.items():\n",
    "    l.append(k)\n",
    "    l = l+v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "l= [ele.replace(\"*\", \"\") for ele in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, True, True, False]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_foreign(sent):\n",
    "    if not sent:\n",
    "            return []\n",
    "    s = re.sub(r'[^\\w\\s]',' ',sent)\n",
    "    doc = nlp(s)\n",
    "    is_foreign = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_==\"GPE\":\n",
    "            is_foreign.append(not(ent.text in l))\n",
    "    return is_foreign\n",
    "\n",
    "extract_foreign(\"India, China Italy, Japan, Pune, 1989 mountains Apple Meghana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def find_travelled(data):\n",
    "    df = data.copy()\n",
    "    df[\"Relationship\"] = df[\"Notes\"].progress_apply(extract_relationship)\n",
    "    df[\"Travel Place\"] = df[\"Notes\"].progress_apply(extract_travel_place)\n",
    "    df[\"Nationality\"] = df[\"Notes\"].progress_apply(extract_nationality)\n",
    "    df[\"is_foreign\"] = df[\"Notes\"].progress_apply(extract_foreign)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:03<00:00, 327.28it/s]\n",
      "100%|██████████| 1040/1040 [00:03<00:00, 330.57it/s]\n",
      "100%|██████████| 1040/1040 [00:03<00:00, 334.87it/s]\n",
      "100%|██████████| 1040/1040 [00:03<00:00, 338.28it/s]\n"
     ]
    }
   ],
   "source": [
    "find_travelled(df).to_csv(\"rel.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
